{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import lib.xmlreader as xml\n",
    "import lib.utils as ut\n",
    "import numpy as np\n",
    "\n",
    "import gensim.models.word2vec\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'rpolarity' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-255b318668f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train_docs = xml.readXML(\"../database/TASS/TASS2018/task1-Training.xml\",[0,1,2,3])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#dev_docs   = xml.readXML(\"../database/TASS/TASS2018/task1-Development.xml\",[0,1,2,3])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_docs\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mxml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadXML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../database/TASS/TASS2018/task1-Test.xml\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documentos/cs/crs/c2/sistemas-inteligentes/final/AdvacedSentimentAnalysis/src/lib/xmlreader.py\u001b[0m in \u001b[0;36mreadXML\u001b[0;34m(xmlFIle, Lvls)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#polarity = treeLevels(polarity)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpolarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolarityTagging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Other info:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/cs/crs/c2/sistemas-inteligentes/final/AdvacedSentimentAnalysis/src/lib/xmlreader.py\u001b[0m in \u001b[0;36mpolarityTagging\u001b[0;34m(polarity)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mrpolarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrpolarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'rpolarity' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#train_docs = xml.readXML(\"../database/TASS/TASS2018/task1-Training.xml\",[0,1,2,3])\n",
    "#dev_docs   = xml.readXML(\"../database/TASS/TASS2018/task1-Development.xml\",[0,1,2,3])\n",
    "test_docs  = xml.readXML(\"../database/TASS/TASS2018/task1-Test.xml\",[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8a34f1cbd6df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_docs' is not defined"
     ]
    }
   ],
   "source": [
    "len(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e4f1497ccfea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_docs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdev_docs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_docs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_docs' is not defined"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "for doc in train_docs + dev_docs + test_docs:\n",
    "    corpus.append(doc.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2928"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_docs + dev_docs + train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "for doc in train_docs:\n",
    "    train_labels.append(doc.polarity)\n",
    "    \n",
    "dev_labels  = []\n",
    "for doc in dev_docs:\n",
    "    dev_labels.append(doc.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensim_load_vec(path=\"../database/embeddings/SBW-vectors-300-min5.bin\"):\n",
    "    #use gensim_emb.wv.index2word if used this way to load vectors\n",
    "    #gensim_emb = gensim.models.word2vec.Word2Vec.load(path)\n",
    "    gensim_emb =  gensim.models.KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "    vocab = gensim_emb.index2word\n",
    "    vec = gensim_emb.syn0\n",
    "    shape = gensim_emb.syn0.shape\n",
    "    return gensim_emb, vec, shape, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \n",
      "/home/jose/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "gensim_emb, vec, shape, vocab = gensim_load_vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = CountVectorizer(tokenizer=ut.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2928, 8706)\n"
     ]
    }
   ],
   "source": [
    "X = counter.fit_transform(corpus)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = np.sum(X, axis=0).tolist()\n",
    "counts = sorted(counts[0], reverse=True)\n",
    "plt.plot(np.arange(len(counts)), counts)\n",
    "plt.title(\"word count distribution in corpus\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.xlabel(\"words\")\n",
    "acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2928, 8706)\n"
     ]
    }
   ],
   "source": [
    "# VOCAB_SIZE = 3000\n",
    "VOCAB_SIZE = X.shape[1]\n",
    "# counter = CountVectorizer(strip_accents=\"unicode\", max_features=VOCAB_SIZE)\n",
    "# counter = CountVectorizer(max_features=VOCAB_SIZE, tokenizer=ut.tokenizer)\n",
    "\n",
    "caption_texts = corpus\n",
    "Xc = counter.fit_transform(caption_texts).todense().astype(\"float\")\n",
    "print(Xc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2928, 1)\n"
     ]
    }
   ],
   "source": [
    "sent_lens = np.sum(Xc, axis=1).astype(\"float\")\n",
    "sent_lens[sent_lens == 0] = 1e-14\n",
    "print(sent_lens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8706, 300)\n"
     ]
    }
   ],
   "source": [
    "E = np.zeros((VOCAB_SIZE, 300))\n",
    "for word in list(counter.vocabulary_.keys()):\n",
    "    try:\n",
    "        i = counter.vocabulary_[word]\n",
    "        E[i] = gensim_emb[word]\n",
    "    except KeyError:\n",
    "        pass\n",
    "print(E.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2928, 300)\n"
     ]
    }
   ],
   "source": [
    "Xb = np.divide(np.dot(Xc, E), sent_lens)\n",
    "print(Xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 300) (1000,) (500, 300) (500,)\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xdev = Xb[0:len(train_docs)], Xb[len(train_docs):len(train_docs)+len(dev_docs)]\n",
    "ytrain, ydev = np.array(train_labels), np.array(dev_labels)\n",
    "print(Xtrain.shape, ytrain.shape, Xdev.shape, ydev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras \n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "from keras.layers import Input, Dense, concatenate, Activation\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "print(K.tensorflow_backend._get_available_gpus())\n",
    "\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=4, \\\n",
    "                        inter_op_parallelism_threads=4, \\\n",
    "                        allow_soft_placement=True,\\\n",
    "                        device_count = {'CPU' : 1, 'GPU' : 0})\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "    \n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 64)                19264     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 19,524\n",
      "Trainable params: 19,524\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tweet_encoder   = Input(shape=(300,), dtype='float32')\n",
    "\n",
    "merged = Dense(256)(tweet_encoder)\n",
    "merged = Dropout(0.5)(merged)\n",
    "\n",
    "merged = Dense(128)(tweet_encoder)\n",
    "merged = Dropout(0.5)(merged)\n",
    "\n",
    "merged = Dense(64)(tweet_encoder)\n",
    "merged = Dropout(0.2)(merged)\n",
    "\n",
    "merged = Dense(4)(merged)\n",
    "output = Activation('softmax')(merged)\n",
    "model  = Model(inputs=[tweet_encoder], outputs=[output])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 0s 469us/step - loss: 1.3612 - acc: 0.3520 - val_loss: 1.2688 - val_acc: 0.4760\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.47600, saving model to model/CNN_best_weights_SIF.01-0.4760.hdf5\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 1.3273 - acc: 0.3740 - val_loss: 1.2665 - val_acc: 0.4820\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.47600 to 0.48200, saving model to model/CNN_best_weights_SIF.02-0.4820.hdf5\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 1.3137 - acc: 0.3740 - val_loss: 1.2498 - val_acc: 0.4880\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.48200 to 0.48800, saving model to model/CNN_best_weights_SIF.03-0.4880.hdf5\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 1.2935 - acc: 0.4260 - val_loss: 1.2359 - val_acc: 0.4820\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.48800\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 1.2693 - acc: 0.4020 - val_loss: 1.2452 - val_acc: 0.4840\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.48800\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 1.2547 - acc: 0.4540 - val_loss: 1.2260 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.48800\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 1.2330 - acc: 0.4560 - val_loss: 1.2178 - val_acc: 0.4780\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.48800\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 1.2220 - acc: 0.4430 - val_loss: 1.2177 - val_acc: 0.4840\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.48800\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 1.2065 - acc: 0.4740 - val_loss: 1.2046 - val_acc: 0.4860\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.48800\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 1.1961 - acc: 0.4800 - val_loss: 1.1953 - val_acc: 0.4920\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.48800 to 0.49200, saving model to model/CNN_best_weights_SIF.10-0.4920.hdf5\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 1.1923 - acc: 0.4840 - val_loss: 1.2322 - val_acc: 0.4760\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.49200\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 1.1712 - acc: 0.4970 - val_loss: 1.1875 - val_acc: 0.4920\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.49200 to 0.49200, saving model to model/CNN_best_weights_SIF.12-0.4920.hdf5\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 1.1666 - acc: 0.4870 - val_loss: 1.1912 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.49200 to 0.50400, saving model to model/CNN_best_weights_SIF.13-0.5040.hdf5\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 1.1436 - acc: 0.5010 - val_loss: 1.1992 - val_acc: 0.4840\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.50400\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 1.1442 - acc: 0.5010 - val_loss: 1.2059 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.50400\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 1.1315 - acc: 0.5150 - val_loss: 1.1734 - val_acc: 0.5080\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.50400 to 0.50800, saving model to model/CNN_best_weights_SIF.16-0.5080.hdf5\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 1.1197 - acc: 0.5110 - val_loss: 1.1859 - val_acc: 0.4840\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.50800\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 1.1141 - acc: 0.5160 - val_loss: 1.1798 - val_acc: 0.4880\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.50800\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 1.1035 - acc: 0.5270 - val_loss: 1.2113 - val_acc: 0.4820\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.50800\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 1.0979 - acc: 0.5190 - val_loss: 1.1804 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.50800\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 1.0915 - acc: 0.5250 - val_loss: 1.1792 - val_acc: 0.4940\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.50800\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 1.0761 - acc: 0.5480 - val_loss: 1.1701 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.50800\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 1.0734 - acc: 0.5450 - val_loss: 1.1980 - val_acc: 0.4880\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.50800\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 1.0690 - acc: 0.5560 - val_loss: 1.2018 - val_acc: 0.4840\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.50800\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 1.0604 - acc: 0.5550 - val_loss: 1.2074 - val_acc: 0.4660\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.50800\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 1.0624 - acc: 0.5470 - val_loss: 1.1724 - val_acc: 0.4860\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.50800\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 1.0550 - acc: 0.5530 - val_loss: 1.1763 - val_acc: 0.4980\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.50800\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 1.0426 - acc: 0.5520 - val_loss: 1.1985 - val_acc: 0.4720\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.50800\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 1.0382 - acc: 0.5600 - val_loss: 1.1869 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.50800\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 1.0261 - acc: 0.5670 - val_loss: 1.1857 - val_acc: 0.4880\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.50800\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 1.0248 - acc: 0.5760 - val_loss: 1.2294 - val_acc: 0.4540\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.50800\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 1.0205 - acc: 0.5630 - val_loss: 1.2142 - val_acc: 0.4660\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.50800\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 1.0166 - acc: 0.5640 - val_loss: 1.2264 - val_acc: 0.4500\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.50800\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 1.0121 - acc: 0.5670 - val_loss: 1.2154 - val_acc: 0.4640\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.50800\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 1.0152 - acc: 0.5760 - val_loss: 1.2052 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.50800\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 1.0026 - acc: 0.5820 - val_loss: 1.1967 - val_acc: 0.4960\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.50800\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 1.0059 - acc: 0.5740 - val_loss: 1.2413 - val_acc: 0.4600\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.50800\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 1.0047 - acc: 0.5740 - val_loss: 1.2324 - val_acc: 0.4600\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.50800\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.9894 - acc: 0.5660 - val_loss: 1.2408 - val_acc: 0.4440\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.50800\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.9787 - acc: 0.5910 - val_loss: 1.1896 - val_acc: 0.4920\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.50800\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.9717 - acc: 0.5920 - val_loss: 1.2189 - val_acc: 0.4520\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.50800\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.9692 - acc: 0.5930 - val_loss: 1.2296 - val_acc: 0.4620\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.50800\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.9816 - acc: 0.5830 - val_loss: 1.2115 - val_acc: 0.4740\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.50800\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.9666 - acc: 0.5960 - val_loss: 1.2237 - val_acc: 0.4620\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.50800\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.9561 - acc: 0.6100 - val_loss: 1.2136 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.50800\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.9562 - acc: 0.6000 - val_loss: 1.2549 - val_acc: 0.4340\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.50800\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.9653 - acc: 0.5900 - val_loss: 1.2794 - val_acc: 0.4420\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.50800\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.9544 - acc: 0.5970 - val_loss: 1.2818 - val_acc: 0.4240\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.50800\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.9483 - acc: 0.6010 - val_loss: 1.2740 - val_acc: 0.4360\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.50800\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.9444 - acc: 0.6050 - val_loss: 1.3066 - val_acc: 0.4320\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.50800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7b90421710>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"model/CNN_best_weights_SIF.{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "model.fit(Xtrain, to_categorical(ytrain), batch_size=64, epochs=50,\n",
    "                     validation_data=(Xdev, to_categorical(ydev)), callbacks = [checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = Xb[-len(test_docs):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "best_model = load_model('model/CNN_best_weights_SIF.22-0.5140.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_result = best_model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1428, 4)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = np.argmax(ytest_result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabel(num):\n",
    "    if num == 0:\n",
    "        return 'N'\n",
    "    elif num == 1:\n",
    "        return 'P'\n",
    "    elif num == 2:\n",
    "        return 'NEU'\n",
    "    elif num == 3:\n",
    "        return 'NONE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def putTestValue(xmlFIle):\n",
    "    tree = ET.parse(xmlFIle)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    tweets = []\n",
    "    file = open(\"output.txt\",\"w\") \n",
    "    for i,tweet in enumerate(root.iter('tweet')):\n",
    "        #content = tweet.find('content').text\n",
    "        #sentiment = tweet.find('sentiment')\n",
    "        \n",
    "        val = getLabel(test_values[i])\n",
    "        #sentiment.find('polarity').find('value').text= val\n",
    "        #polarity = sentiment.find('polarity').find('value').text\n",
    "        ID = tweet.find('tweetid').text\n",
    "        file.write(ID + \"\\t\" + val + \"\\n\")\n",
    "        #print(polarity)\n",
    "    \n",
    "    file.close() \n",
    "    #mydata = ET.ElementTree(root)  \n",
    "    #myfile = open(\"output.xml\", \"w\")  \n",
    "    #mydata.write(\"output.xml\")  \n",
    "    #return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../database/TASS/TASS2018/intertass-PE-test.xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e1f2381cf41c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mputTestValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../database/TASS/TASS2018/intertass-PE-test.xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-7183b646c29d>\u001b[0m in \u001b[0;36mputTestValue\u001b[0;34m(xmlFIle)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mputTestValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmlFIle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmlFIle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(source, parser)\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \"\"\"\n\u001b[1;32m   1195\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElementTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source, parser)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mclose_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m             \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0mclose_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../database/TASS/TASS2018/intertass-PE-test.xml'"
     ]
    }
   ],
   "source": [
    "\n",
    "putTestValue(\"../database/TASS/TASS2018/intertass-PE-test.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(\"../database/TASS/TASS2018/task1-Test.xml\")\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = next(root.iter('tweet'))\n",
    "sentiment = tweet.find('sentiment')\n",
    "type(sentiment.find('polarity').find('value').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.find('polarity').find('value').text == "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None in [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NotImplemented"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None.__eq__('N+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
