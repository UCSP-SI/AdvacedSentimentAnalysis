{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.xmlreader as xml\n",
    "import lib.utils as ut\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim.models.word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = xml.readXML(\"../database/TASS/TASS2018/task1-Training.xml\",[0,1,2,3])\n",
    "val_docs   = xml.readXML(\"../database/TASS/TASS2018/task1-Development.xml\",[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets = []\n",
    "train_labels = []\n",
    "for doc in train_docs:\n",
    "    # train_tweets.append(ut.tokenize(doc.content, 0)['clean'])\n",
    "    train_tweets.append(doc.content)\n",
    "    train_labels.append(doc.polarity)\n",
    "\n",
    "val_tweets = []\n",
    "val_labels = []\n",
    "for doc in val_docs:\n",
    "    # test_tweets.append(ut.tokenize(doc.content, 0)['clean'])\n",
    "    val_tweets.append(doc.content)\n",
    "    val_labels.append(doc.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tweets), len(val_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sentences = 242\n",
      "       \r",
      "Negative Sentences = 231\n",
      "       \r",
      "Neutral  Sentences = 166\n",
      "       \r",
      "None Values        = 361\n"
     ]
    }
   ],
   "source": [
    "POSI_train_docs = [train_docs[i] for i in range(len(train_labels)) if train_labels[i] == 0]\n",
    "NEGA_train_docs = [train_docs[i] for i in range(len(train_labels)) if train_labels[i] == 1]\n",
    "NEUT_train_docs = [train_docs[i] for i in range(len(train_labels)) if train_labels[i] == 2]\n",
    "NONE_train_docs = [train_docs[i] for i in range(len(train_labels)) if train_labels[i] == 3]\n",
    "\n",
    "level_train_docs = [POSI_train_docs,NEGA_train_docs,NEUT_train_docs,NONE_train_docs]\n",
    "\n",
    "fmt = \"\"\"Positive Sentences = {:d}\n",
    "       \\rNegative Sentences = {:d}\n",
    "       \\rNeutral  Sentences = {:d}\n",
    "       \\rNone Values        = {:d}\"\"\"\n",
    "\n",
    "print(fmt.format(len(POSI_train_docs),\n",
    "                 len(NEGA_train_docs),\n",
    "                 len(NEUT_train_docs),\n",
    "                 len(NONE_train_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of sentences per level :  166\n"
     ]
    }
   ],
   "source": [
    "minSentLvl = min(len(POSI_train_docs),len(NEGA_train_docs),len(NEUT_train_docs),len(NONE_train_docs))\n",
    "\n",
    "print('Minimum number of sentences per level : ', minSentLvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "new_train_docs = []\n",
    "for i in range(len(level_train_docs)):\n",
    "    level_per = random.sample(level_train_docs[i],len(level_train_docs[i]))\n",
    "    new_train_docs.append(level_per[:minSentLvl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New size of sentences:\n",
      "\n",
      "Positive Sentences = 166\n",
      "       \r",
      "Negative Sentences = 166\n",
      "       \r",
      "Neutral  Sentences = 166\n",
      "       \r",
      "None Values        = 166\n"
     ]
    }
   ],
   "source": [
    "print(\"New size of sentences:\\n\")\n",
    "fmt = \"\"\"Positive Sentences = {:d}\n",
    "       \\rNegative Sentences = {:d}\n",
    "       \\rNeutral  Sentences = {:d}\n",
    "       \\rNone Values        = {:d}\"\"\"\n",
    "\n",
    "print(fmt.format(len(new_train_docs[0]),\n",
    "                 len(new_train_docs[1]),\n",
    "                 len(new_train_docs[2]),\n",
    "                 len(new_train_docs[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuf_train_docs size =  664\n"
     ]
    }
   ],
   "source": [
    "flat_train_docs = [item for sublist in new_train_docs for item in sublist]\n",
    "shuf_train_docs = random.sample(flat_train_docs,len(flat_train_docs))\n",
    "\n",
    "assert (len(shuf_train_docs) == 4 * minSentLvl)\n",
    "print(\"shuf_train_docs size = \", len(shuf_train_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for doc in shuf_train_docs + val_docs:\n",
    "    corpus.append(doc.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences =  1164\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences = \", (len(val_docs + shuf_train_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuf_train_labels = []\n",
    "for doc in shuf_train_docs:\n",
    "    shuf_train_labels.append(doc.polarity)\n",
    "    \n",
    "assert (len(shuf_train_labels) == len(shuf_train_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = CountVectorizer(tokenizer=ut.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1164, 4574)\n"
     ]
    }
   ],
   "source": [
    "X = counter.fit_transform(corpus)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs   = xml.readXMLTest(\"../database/TASS/TASS2018/task1-Test.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = []\n",
    "for doc in test_docs:\n",
    "    test_tweets.append(doc.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(test_tweets) == 1428)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for tweet in corpus + test_tweets:\n",
    "    sentence = []\n",
    "    for word in ut.tokenizer(tweet):\n",
    "        sentence.append(word)\n",
    "    sequences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(sequences) == (len(shuf_train_docs) + len(val_docs) + len(test_tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter(word for doc in sequences for word in doc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 8025)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt['felicidad'], len(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('activacion', 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.most_common()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('que', 1451),\n",
       " ('de', 1222),\n",
       " ('y', 1034),\n",
       " ('a', 913),\n",
       " ('no', 855),\n",
       " ('la', 802),\n",
       " ('me', 730),\n",
       " ('el', 722),\n",
       " ('en', 661),\n",
       " ('es', 565)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8027"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "max_vocab = len(cnt)\n",
    "min_freq = 0\n",
    "#max_vocab = len(cnt)\n",
    "#max_vocab = 4000\n",
    "#min_freq  = 0\n",
    "\n",
    "\n",
    "itos = [o for o,c in cnt.most_common(max_vocab) if c >= min_freq]\n",
    "\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')\n",
    "\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8025\n"
     ]
    }
   ],
   "source": [
    "print(len(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8027"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(itos, open('../database/ulmfit/tmp/itos_'+'2018'+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos      = pickle.load(open('../database/ulmfit/tmp/itos_'+'2018'+'.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ids = [[stoi[o] for o in p] for p in sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(sequences) == len(data_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data train tensor: (664,)\n",
      "Shape of data val  tensor: (500,)\n",
      "Shape of data test  tensor: (1428,)\n"
     ]
    }
   ],
   "source": [
    "x_train_ids = np.array(data_ids[:len(shuf_train_labels)])\n",
    "x_val_ids   = np.array(data_ids[len(shuf_train_labels):len(shuf_train_labels)+len(val_docs)])\n",
    "x_test_ids  = np.array(data_ids[(len(shuf_train_labels)+len(val_docs)):])\n",
    "\n",
    "print('Shape of data train tensor:', x_train_ids.shape)\n",
    "print('Shape of data val  tensor:', x_val_ids.shape)\n",
    "print('Shape of data test  tensor:', x_test_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = '../database/ulmfit/'\n",
    "TASS_     = '2018'\n",
    "np.save(SAVE_PATH + \"tmp/train_labels_\"+TASS_+\".npy\",shuf_train_labels)\n",
    "np.save(SAVE_PATH + \"tmp/val_labels_\"+TASS_+\".npy\",val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(SAVE_PATH + \"tmp/train_ids_\"+TASS_+\".npy\",x_train_ids)\n",
    "np.save(SAVE_PATH + \"tmp/val_ids_\"+TASS_+\".npy\",x_val_ids)\n",
    "np.save(SAVE_PATH + \"tmp/test_ids_\"+TASS_+\".npy\",x_test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ya',\n",
       " 'me',\n",
       " 'imagino',\n",
       " 'su',\n",
       " 'calor',\n",
       " 'que',\n",
       " 'debe',\n",
       " 'estar',\n",
       " 'haciendo',\n",
       " 'alla',\n",
       " 'ya',\n",
       " 'me',\n",
       " 'imagino',\n",
       " 'negr']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_',\n",
       " '_pad_',\n",
       " 'que',\n",
       " 'de',\n",
       " 'y',\n",
       " 'a',\n",
       " 'no',\n",
       " 'la',\n",
       " 'me',\n",
       " 'el',\n",
       " 'en',\n",
       " 'es',\n",
       " 'mi',\n",
       " 'lo',\n",
       " 'un',\n",
       " 'se',\n",
       " 'por',\n",
       " 'con',\n",
       " 'te',\n",
       " 'los',\n",
       " 'pero',\n",
       " 'ya',\n",
       " 'para',\n",
       " 'si',\n",
       " 'una',\n",
       " 'yo',\n",
       " 'las',\n",
       " 'mas',\n",
       " 'como',\n",
       " 'todo',\n",
       " 'o',\n",
       " 'al',\n",
       " 'tu',\n",
       " 'solo',\n",
       " 'del',\n",
       " 'esta',\n",
       " 'cuando',\n",
       " 'quiero',\n",
       " 'dia',\n",
       " 'porque',\n",
       " 'mejor',\n",
       " 'estoy',\n",
       " 'hoy',\n",
       " 'muy',\n",
       " 'tengo',\n",
       " 'feliz',\n",
       " 'eso',\n",
       " 'bueno',\n",
       " 'q',\n",
       " 'mis',\n",
       " 'su',\n",
       " 'bien',\n",
       " 'siempre',\n",
       " 'le',\n",
       " 'ser',\n",
       " 'ahora',\n",
       " 'extra',\n",
       " 'todos',\n",
       " 'sin',\n",
       " 'este',\n",
       " 'gracias',\n",
       " 'ver',\n",
       " 'hay',\n",
       " 'asi',\n",
       " 'buen',\n",
       " 'os',\n",
       " 'hace',\n",
       " 'tan',\n",
       " 'son',\n",
       " 'vida',\n",
       " 'fue',\n",
       " 'ni',\n",
       " 'soy',\n",
       " 'ao',\n",
       " 'nos',\n",
       " 'ma',\n",
       " 'hacer',\n",
       " 'nada',\n",
       " 'mucho',\n",
       " 'hasta',\n",
       " 'eres',\n",
       " 'ir',\n",
       " 'dias',\n",
       " 'he',\n",
       " 'estar',\n",
       " 'buena',\n",
       " 'algo',\n",
       " 'ana',\n",
       " 'igual',\n",
       " 'sea',\n",
       " 'desde',\n",
       " 'cosas',\n",
       " 'tiempo',\n",
       " 'nuevo',\n",
       " 'vez',\n",
       " 'tambien',\n",
       " 'peru',\n",
       " 'voy',\n",
       " 'ese',\n",
       " 'sus',\n",
       " 'espero',\n",
       " 'tus',\n",
       " 'aun',\n",
       " 'ti',\n",
       " 'esa',\n",
       " 'semana',\n",
       " 'estas',\n",
       " 'va',\n",
       " 'creo',\n",
       " 'sera',\n",
       " 'donde',\n",
       " 'cada',\n",
       " 'puedo',\n",
       " 'hola',\n",
       " 'mal',\n",
       " 'menos',\n",
       " 'siento',\n",
       " 'nunca',\n",
       " 'uno',\n",
       " 'tener',\n",
       " 'nadie',\n",
       " 'lindo',\n",
       " 'les',\n",
       " 'pues',\n",
       " 'casa',\n",
       " 'aqui',\n",
       " 'era',\n",
       " 'veo',\n",
       " 'da',\n",
       " 'ha',\n",
       " 'jaja',\n",
       " 'amor',\n",
       " 'salir',\n",
       " 'triste',\n",
       " 'tiene',\n",
       " 'fin',\n",
       " 'mismo',\n",
       " 'sue',\n",
       " 'jajajaja',\n",
       " 'estan',\n",
       " 'peor',\n",
       " 'cumplea',\n",
       " 'alguien',\n",
       " 'dios',\n",
       " 'navidad',\n",
       " 'jajaja',\n",
       " 'gran',\n",
       " 'saludos',\n",
       " 'serio',\n",
       " 'pasa',\n",
       " 'tienes',\n",
       " 'toda',\n",
       " 'quien',\n",
       " 'ojala',\n",
       " 'momento',\n",
       " 'persona',\n",
       " 'bonito',\n",
       " 'corazon',\n",
       " 'mundo',\n",
       " 'mama',\n",
       " 'final',\n",
       " 'antes',\n",
       " 'familia',\n",
       " 'otro',\n",
       " 'paso',\n",
       " 'dos',\n",
       " 'gusta',\n",
       " 'otra',\n",
       " 'decir',\n",
       " 'ah',\n",
       " 'noche',\n",
       " 'ayer',\n",
       " 'dormir',\n",
       " 'amiga',\n",
       " 'gente',\n",
       " 'luego',\n",
       " 'ultimo',\n",
       " 'dice',\n",
       " 'esto',\n",
       " 'muchas',\n",
       " 'as',\n",
       " 'seguro',\n",
       " 'ganas',\n",
       " 'aunque',\n",
       " 'buenos',\n",
       " 'hora',\n",
       " 'tanto',\n",
       " 'amigo',\n",
       " 'puede',\n",
       " 'van',\n",
       " 'ella',\n",
       " 'amigos',\n",
       " 'hecho',\n",
       " 'todas',\n",
       " 'poco',\n",
       " 'personas',\n",
       " 'di',\n",
       " 'tarde',\n",
       " 'genial',\n",
       " 'claro',\n",
       " 'unico',\n",
       " 'quiere',\n",
       " 'verdad',\n",
       " 'amo',\n",
       " 'cuenta',\n",
       " 'rico',\n",
       " 'sido',\n",
       " 'ay',\n",
       " 'poder',\n",
       " 'despues',\n",
       " 'queria',\n",
       " 'felices',\n",
       " 'estos',\n",
       " 'malo',\n",
       " 'mes',\n",
       " 'nueva',\n",
       " 'trabajo',\n",
       " 'dicen',\n",
       " 'vas',\n",
       " 'vamos',\n",
       " 'seria',\n",
       " 'feli',\n",
       " 'bonita',\n",
       " 'lima',\n",
       " 'mejores',\n",
       " 'primera',\n",
       " 'unos',\n",
       " 'fui',\n",
       " 'e',\n",
       " 'sigo',\n",
       " 'super',\n",
       " 'ahi',\n",
       " 'odio',\n",
       " 'horas',\n",
       " 'esos',\n",
       " 'dio',\n",
       " 've',\n",
       " 'sigue',\n",
       " 'hermoso',\n",
       " 'cierto',\n",
       " 'queda',\n",
       " 'llorar',\n",
       " 'han',\n",
       " 'casi',\n",
       " 'veces',\n",
       " 'necesito',\n",
       " 'parece',\n",
       " 'video',\n",
       " 'trabajar',\n",
       " 'buenas',\n",
       " 'justo',\n",
       " 'estaba',\n",
       " 'caso',\n",
       " 'demasiado',\n",
       " 'abrazo',\n",
       " 'pasado',\n",
       " 'acabo',\n",
       " 'dolor',\n",
       " 'papa',\n",
       " 'saludo',\n",
       " 'primer',\n",
       " 'pasar',\n",
       " 'vid',\n",
       " 'viendo',\n",
       " 'x',\n",
       " 'sabes',\n",
       " 'hermosa',\n",
       " 'sol',\n",
       " 'comer',\n",
       " 'peque',\n",
       " 'tod',\n",
       " 'cancion',\n",
       " 'pronto',\n",
       " 'vi',\n",
       " 'am',\n",
       " 'seguir',\n",
       " 'momentos',\n",
       " 'falta',\n",
       " 'primero',\n",
       " 'sola',\n",
       " 'habia',\n",
       " 'tomar',\n",
       " 'nuestro',\n",
       " 'xq',\n",
       " 'forma',\n",
       " 'escuchar',\n",
       " 'feo',\n",
       " 'esas',\n",
       " 'contigo',\n",
       " 'mierda',\n",
       " 'torta',\n",
       " 'lunes',\n",
       " 'sentir',\n",
       " 'pa',\n",
       " 'hare',\n",
       " 'ar',\n",
       " 'tal',\n",
       " 'haya',\n",
       " 'regalo',\n",
       " 'chico',\n",
       " 'poner',\n",
       " 'favor',\n",
       " 'quieres',\n",
       " 'debo',\n",
       " 'entiendo',\n",
       " 'jajaj',\n",
       " 'algun',\n",
       " 'dificil',\n",
       " 'fuerte',\n",
       " 'proxima',\n",
       " 'mejo',\n",
       " 'lado',\n",
       " 'debe',\n",
       " 'importa',\n",
       " 'per',\n",
       " 'quisiera',\n",
       " 'cas',\n",
       " 'pobre',\n",
       " 'siendo',\n",
       " 'entre',\n",
       " 'tenia',\n",
       " 'linda',\n",
       " 'unas',\n",
       " 'dar',\n",
       " 'so',\n",
       " 'sobre',\n",
       " 'ptm',\n",
       " 'quedo',\n",
       " 'sale',\n",
       " 'u',\n",
       " 'musica',\n",
       " 'medio',\n",
       " 'libre',\n",
       " 'llegar',\n",
       " 'volver',\n",
       " 'fe',\n",
       " 'chamba',\n",
       " 'pude',\n",
       " 'haces',\n",
       " 'twitter',\n",
       " 'foto',\n",
       " 'junto',\n",
       " 'hago',\n",
       " 'canciones',\n",
       " 'tenemos',\n",
       " 'exitos',\n",
       " 're',\n",
       " 'mism',\n",
       " 'unica',\n",
       " 'lugar',\n",
       " 'visto',\n",
       " 'cuanto',\n",
       " 'quieren',\n",
       " 'nuevos',\n",
       " 'hacen',\n",
       " 'viernes',\n",
       " 'viene',\n",
       " 'pena',\n",
       " 'dormido',\n",
       " 'oa',\n",
       " 'ciclo',\n",
       " 'mala',\n",
       " 'hermana',\n",
       " 'd',\n",
       " 'muchos',\n",
       " 'videos',\n",
       " 'maldito',\n",
       " 'quede',\n",
       " 'toca',\n",
       " 'haciendo',\n",
       " 'pais',\n",
       " 'recuerdo',\n",
       " 'lleno',\n",
       " 'ire',\n",
       " 'cual',\n",
       " 'monton',\n",
       " 'sabado',\n",
       " 'creer',\n",
       " 'puedes',\n",
       " 'fueron',\n",
       " 'tipo',\n",
       " 'proximo',\n",
       " 'clase',\n",
       " 'encanta',\n",
       " 'dinero',\n",
       " 'felicidad',\n",
       " 'vale',\n",
       " 'tienen',\n",
       " 'saber',\n",
       " 'domingo',\n",
       " 'iba',\n",
       " 'somos',\n",
       " 'comida',\n",
       " 'oye',\n",
       " 'llega',\n",
       " 'haga',\n",
       " 'cabeza',\n",
       " 'hizo',\n",
       " 'parte',\n",
       " 'acaba',\n",
       " 'normal',\n",
       " 'venir',\n",
       " 'hambre',\n",
       " 'pe',\n",
       " 'horrible',\n",
       " 'excelente',\n",
       " 'tenido',\n",
       " 'dije',\n",
       " 'aveces',\n",
       " 'pone',\n",
       " 'deseo',\n",
       " 'misma',\n",
       " 'pueden',\n",
       " 'juntos',\n",
       " 'has',\n",
       " 'nota',\n",
       " 'sabe',\n",
       " 'facil',\n",
       " 'tengas',\n",
       " 'hayas',\n",
       " 'deja',\n",
       " 'pasan',\n",
       " 'esperando',\n",
       " 'viaje',\n",
       " 'jajajajaja',\n",
       " 'hagas',\n",
       " 'salga',\n",
       " 'vivir',\n",
       " 'ense',\n",
       " 'pense',\n",
       " 'cama',\n",
       " 'cine',\n",
       " 'mil',\n",
       " 'dijo',\n",
       " 'problemas',\n",
       " 'rato',\n",
       " 'aca',\n",
       " 'quedan',\n",
       " 'ex',\n",
       " 'ho',\n",
       " 'recien',\n",
       " 'concierto',\n",
       " 'realidad',\n",
       " 'cosa',\n",
       " 'csm',\n",
       " 'nuev',\n",
       " 'doy',\n",
       " 'encuentro',\n",
       " 'hombre',\n",
       " 'verte',\n",
       " 'importante',\n",
       " 'terminar',\n",
       " 'muero',\n",
       " 'cafe',\n",
       " 'digo',\n",
       " 'conmigo',\n",
       " 'hermano',\n",
       " 'jajajaj',\n",
       " 'palabras',\n",
       " 'pasala',\n",
       " 'meses',\n",
       " 'oy',\n",
       " 'amig',\n",
       " 'grande',\n",
       " 'feriado',\n",
       " 'trafico',\n",
       " 'llego',\n",
       " 'nad',\n",
       " 'chicos',\n",
       " 'todavia',\n",
       " 'celular',\n",
       " 'comprar',\n",
       " 'ven',\n",
       " 'ja',\n",
       " 'san',\n",
       " 'sabia',\n",
       " 'hubiera',\n",
       " 'ok',\n",
       " 'compa',\n",
       " 'hombres',\n",
       " 'adelante',\n",
       " 'ultima',\n",
       " 'jamas',\n",
       " 'fuera',\n",
       " 'navide',\n",
       " 'vino',\n",
       " 'pensar',\n",
       " 'inicio',\n",
       " 'seman',\n",
       " 'amigas',\n",
       " 'alto',\n",
       " 'rt',\n",
       " 'cuerpo',\n",
       " 'cansada',\n",
       " 'noticia',\n",
       " 'vere',\n",
       " 'estamos',\n",
       " 'acuerdo',\n",
       " 'tenga',\n",
       " 'tuve',\n",
       " 'pienso',\n",
       " 'encima',\n",
       " 'pasando',\n",
       " 'conocer',\n",
       " 'entonces',\n",
       " 'cuarto',\n",
       " 'bella',\n",
       " 'culpa',\n",
       " 'calle',\n",
       " 'decirte',\n",
       " 'pase',\n",
       " 'tampoco',\n",
       " 'llevo',\n",
       " 'salida',\n",
       " 'canal',\n",
       " 'chevere',\n",
       " 'termine',\n",
       " 'ellos',\n",
       " 'quier',\n",
       " 'diciembre',\n",
       " 'mucha',\n",
       " 'vivo',\n",
       " 'bie',\n",
       " 'cara',\n",
       " 'examen',\n",
       " 'hice',\n",
       " 'cualquier',\n",
       " 'gusto',\n",
       " 'chica',\n",
       " 'jaj',\n",
       " 'par',\n",
       " 'duele',\n",
       " 'largo',\n",
       " 'increible',\n",
       " 'baby',\n",
       " 'rica',\n",
       " 'empieza',\n",
       " 'manera',\n",
       " 'soles',\n",
       " 'do',\n",
       " 'posible',\n",
       " 'trabajos',\n",
       " 'frio',\n",
       " 'alla',\n",
       " 'enero',\n",
       " 'manos',\n",
       " 'tranquilo',\n",
       " 'puse',\n",
       " 'siguiente',\n",
       " 'miedo',\n",
       " 'miercoles',\n",
       " 'lindos',\n",
       " 'diferente',\n",
       " 'semanas',\n",
       " 'like',\n",
       " 'podria',\n",
       " 'subir',\n",
       " 'fotos',\n",
       " 'pregunto',\n",
       " 'llena',\n",
       " 'cumple',\n",
       " 'tiempos',\n",
       " 'universidad',\n",
       " 'ojos',\n",
       " 'i',\n",
       " 'ayuda',\n",
       " 'gracia',\n",
       " 'sonrisa',\n",
       " 'nuestros',\n",
       " 'podre',\n",
       " 'dormida',\n",
       " 'clases',\n",
       " 'saben',\n",
       " 'recuerda',\n",
       " 'demas',\n",
       " 'humor',\n",
       " 'otros',\n",
       " 'abuela',\n",
       " 'dm',\n",
       " 'estudiar',\n",
       " 'luz',\n",
       " 'quiera',\n",
       " 'pos',\n",
       " 'estare',\n",
       " 'mujer',\n",
       " 'estado',\n",
       " 'maximo',\n",
       " 'plaza',\n",
       " 'mayoria',\n",
       " 'pan',\n",
       " 'k',\n",
       " 'especial',\n",
       " 'programa',\n",
       " 'idea',\n",
       " 'completa',\n",
       " 'hablar',\n",
       " 'grandes',\n",
       " 'deberia',\n",
       " 'hagan',\n",
       " 'ultimas',\n",
       " 'ustedes',\n",
       " 'perdon',\n",
       " 'realmente',\n",
       " 'mrd',\n",
       " 'vacaciones',\n",
       " 'ropa',\n",
       " 'compre',\n",
       " 'temprano',\n",
       " 'letra',\n",
       " 'bajo',\n",
       " 'sepa',\n",
       " 'mente',\n",
       " 'dan',\n",
       " 'tema',\n",
       " 'poquito',\n",
       " 'olvidada',\n",
       " 'maldita',\n",
       " 'bello',\n",
       " 'to',\n",
       " 'alegre',\n",
       " 'sino',\n",
       " 'diciendo',\n",
       " 'capitulo',\n",
       " 'juego',\n",
       " 'paz',\n",
       " 'internet',\n",
       " 'gratis',\n",
       " 'tmr',\n",
       " 'pesar',\n",
       " 'or',\n",
       " 'madre',\n",
       " 'haber',\n",
       " 'gym',\n",
       " 'viste',\n",
       " 'llegue',\n",
       " 'finale',\n",
       " 'nuestra',\n",
       " 'entro',\n",
       " 'alg',\n",
       " 'sere',\n",
       " 'nombre',\n",
       " 'real',\n",
       " 'version',\n",
       " 'uu',\n",
       " 'sentimiento',\n",
       " 'sensacion',\n",
       " 'llamo',\n",
       " 'cae',\n",
       " 'felicitaciones',\n",
       " 'oportunidad',\n",
       " 'youtube',\n",
       " 'raro',\n",
       " 'simplemente',\n",
       " 'dices',\n",
       " 'futuro',\n",
       " 'aoy',\n",
       " 'guapo',\n",
       " 'escuchando',\n",
       " 'radio',\n",
       " 'fb',\n",
       " 'helado',\n",
       " 'escucha',\n",
       " 'shaky',\n",
       " 'sean',\n",
       " 'dejar',\n",
       " 'edad',\n",
       " 'fecha',\n",
       " 'hacerlo',\n",
       " 'osea',\n",
       " 'mano',\n",
       " 'pm',\n",
       " 'llegado',\n",
       " 'numero',\n",
       " 'almorzar',\n",
       " 'regreso',\n",
       " 'queremos',\n",
       " 'baja',\n",
       " 'verla',\n",
       " 'ando',\n",
       " 'querer',\n",
       " 'problema',\n",
       " 'partido',\n",
       " 'igua',\n",
       " 'siente',\n",
       " 'secreto',\n",
       " 'tome',\n",
       " 'lastima',\n",
       " 'vemos',\n",
       " 'mientras',\n",
       " 'trata',\n",
       " 'cari',\n",
       " 'tv',\n",
       " 'entrar',\n",
       " 'nomas',\n",
       " 'horario',\n",
       " 'luga',\n",
       " 'puesto',\n",
       " 'min',\n",
       " 'amar',\n",
       " 'luna',\n",
       " 'the',\n",
       " 'equipo',\n",
       " 'verano',\n",
       " 'sentido',\n",
       " 'brasil',\n",
       " 'bendiciones',\n",
       " 'car',\n",
       " 'naturaleza',\n",
       " 'chocolate',\n",
       " 'gust',\n",
       " 'perugraciasporvaloraramic',\n",
       " 'omar',\n",
       " 'gringaaaa',\n",
       " 'listo',\n",
       " 'directo',\n",
       " 'quedarme',\n",
       " 'paneton',\n",
       " 'jefe',\n",
       " 'duro',\n",
       " 'lindas',\n",
       " 'gustaria',\n",
       " 'sigamos',\n",
       " 'felice',\n",
       " 'siii',\n",
       " 'mayor',\n",
       " 'cambio',\n",
       " 'mando',\n",
       " 'nuestras',\n",
       " 'maneras',\n",
       " 'fea',\n",
       " 'lind',\n",
       " 'serie',\n",
       " 'peruano',\n",
       " 'lim',\n",
       " 'escucho',\n",
       " 'conoces',\n",
       " 'joda',\n",
       " 'bonit',\n",
       " 'ves',\n",
       " 'pongo',\n",
       " 'segundo',\n",
       " 'area',\n",
       " 'pudo',\n",
       " 'ell',\n",
       " 'pollo',\n",
       " 'navida',\n",
       " 'olvide',\n",
       " 'gana',\n",
       " 'perro',\n",
       " 'anda',\n",
       " 'dentro',\n",
       " 'tio',\n",
       " 'distancia',\n",
       " 'full',\n",
       " 'encontrar',\n",
       " 'porf',\n",
       " 'duda',\n",
       " 'respuesta',\n",
       " 'comentarios',\n",
       " 'mejore',\n",
       " 'tres',\n",
       " 'pensando',\n",
       " 'pica',\n",
       " 'vicicont',\n",
       " 'segur',\n",
       " 'podia',\n",
       " 'reir',\n",
       " 'aburrido',\n",
       " 'acerca',\n",
       " 'ceviche',\n",
       " 'suerte',\n",
       " 'mu',\n",
       " 'esfuerzo',\n",
       " 'arequipa',\n",
       " 'imelda',\n",
       " 'pueda',\n",
       " 'entradas',\n",
       " 'muriendo',\n",
       " 'punto',\n",
       " 'veras',\n",
       " 'recordar',\n",
       " 'tesis',\n",
       " 'sal',\n",
       " 'deje',\n",
       " 'algunos',\n",
       " 'romantica',\n",
       " 'seres',\n",
       " 'querido',\n",
       " 'termino',\n",
       " 'carro',\n",
       " 'centro',\n",
       " 'trabaj',\n",
       " 'caeli',\n",
       " 'oh',\n",
       " 'oficina',\n",
       " 'pasen',\n",
       " 'irme',\n",
       " 'bajar',\n",
       " 'agua',\n",
       " 'ala',\n",
       " 'rio',\n",
       " 'fondo',\n",
       " 'dicho',\n",
       " 'hablan',\n",
       " 'estara',\n",
       " 'toco',\n",
       " 'error',\n",
       " 'tengan',\n",
       " 'vaya',\n",
       " 'viajar',\n",
       " 'pelicula',\n",
       " 'apenas',\n",
       " 'futbol',\n",
       " 'fiesta',\n",
       " 'ta',\n",
       " 'salen',\n",
       " 'escribir',\n",
       " 'jajajajajaja',\n",
       " 'esperamos',\n",
       " 'peo',\n",
       " 'ale',\n",
       " 'prox',\n",
       " 'alegria',\n",
       " 'alegra',\n",
       " 'presente',\n",
       " 'vuelvo',\n",
       " 'app',\n",
       " 'fiestas',\n",
       " 'pases',\n",
       " 'mar',\n",
       " 'saliendo',\n",
       " 'dire',\n",
       " 'jueves',\n",
       " 'vamo',\n",
       " 'alma',\n",
       " 'rapido',\n",
       " 'cel',\n",
       " 'ultimos',\n",
       " 'seran',\n",
       " 'puta',\n",
       " 'mam',\n",
       " 'guste',\n",
       " 'tomo',\n",
       " 'tierra',\n",
       " 'senti',\n",
       " 'dejes',\n",
       " 'digan',\n",
       " 'despertar',\n",
       " 'salud',\n",
       " 'perfecta',\n",
       " 'dulce',\n",
       " 'padre',\n",
       " 'etc',\n",
       " 'are',\n",
       " 'ia',\n",
       " 'tantos',\n",
       " 'tb',\n",
       " 'minutos',\n",
       " 'miguel',\n",
       " 'esperar',\n",
       " 'dado',\n",
       " 'ello',\n",
       " 'trabaja',\n",
       " 'princesa',\n",
       " 'vayan',\n",
       " 'sales',\n",
       " 'recuerdos',\n",
       " 'china',\n",
       " 'tard',\n",
       " 'acompa',\n",
       " 't',\n",
       " 'admiro',\n",
       " 'carrera',\n",
       " 'roja',\n",
       " 'perfecto',\n",
       " 'hacia',\n",
       " 'on',\n",
       " 'ademas',\n",
       " 'muere',\n",
       " 'imagino',\n",
       " 'estudio',\n",
       " 'alianza',\n",
       " 'intente',\n",
       " 'lagrimas',\n",
       " 'despedida',\n",
       " 'teng',\n",
       " 'camino',\n",
       " 'ejercicios',\n",
       " 'subi',\n",
       " 'alta',\n",
       " 'quise',\n",
       " 'recorde',\n",
       " 'series',\n",
       " 'noch',\n",
       " 'dibuje',\n",
       " 'mercado',\n",
       " 'tristes',\n",
       " 'p',\n",
       " 'ingles',\n",
       " 'gorda',\n",
       " 'instagram',\n",
       " 'caliente',\n",
       " 'estupido',\n",
       " 'sincero',\n",
       " 'termina',\n",
       " 'paro',\n",
       " 'apec',\n",
       " 'gritar',\n",
       " 'ba',\n",
       " 'favorito',\n",
       " 'queso',\n",
       " 'pierdo',\n",
       " 'bebe',\n",
       " 'bonitas',\n",
       " 'detalle',\n",
       " 'rojo',\n",
       " 'otras',\n",
       " 'jodida',\n",
       " 'mr',\n",
       " 'loco',\n",
       " 'libros',\n",
       " 'estuviera',\n",
       " 'puro',\n",
       " 'profe',\n",
       " 'good',\n",
       " 'happy',\n",
       " 'ito',\n",
       " 'terminas',\n",
       " 'mensaje',\n",
       " 'papas',\n",
       " 'polo',\n",
       " 'tuvo',\n",
       " 'combate',\n",
       " 'negativa',\n",
       " 'prefiero',\n",
       " 'yixing',\n",
       " 'busca',\n",
       " 'amado',\n",
       " 'enviar',\n",
       " 'hicieron',\n",
       " 'hubiese',\n",
       " 'incluso',\n",
       " 'ama',\n",
       " 'hey',\n",
       " 'onda',\n",
       " 'spotify',\n",
       " 'disco',\n",
       " 'pela',\n",
       " 'conozco',\n",
       " 'vibra',\n",
       " 'usar',\n",
       " 'reales',\n",
       " 'sonrie',\n",
       " 'vive',\n",
       " 'nuevas',\n",
       " 'preocupes',\n",
       " 'pagar',\n",
       " 'azul',\n",
       " 'mica',\n",
       " 'publico',\n",
       " 'dms',\n",
       " 'sonido',\n",
       " 'novia',\n",
       " 'cuento',\n",
       " 'disfrutar',\n",
       " 'descanso',\n",
       " 'muerte',\n",
       " 'seguire',\n",
       " 'trabajando',\n",
       " 'general',\n",
       " 'zapatillas',\n",
       " 'salgo',\n",
       " 'flaca',\n",
       " 'bailando',\n",
       " 'empiezo',\n",
       " 'cerca',\n",
       " 'mamita',\n",
       " 'apoyo',\n",
       " 'empezar',\n",
       " 'lejos',\n",
       " 'juega',\n",
       " 'dijeron',\n",
       " 'necesitaba',\n",
       " 'famili',\n",
       " 'almuerzo',\n",
       " 'vienen',\n",
       " 'espalda',\n",
       " 'obvio',\n",
       " 'peliculas',\n",
       " 'ole',\n",
       " 'pierda',\n",
       " 'rafael',\n",
       " 'dale',\n",
       " 'relacion',\n",
       " 'pocos',\n",
       " 'uds',\n",
       " 'jugar',\n",
       " 'pas',\n",
       " 'color',\n",
       " 'conoci',\n",
       " ...]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
