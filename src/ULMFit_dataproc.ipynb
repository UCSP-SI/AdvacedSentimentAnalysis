{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.xmlreader as xml\n",
    "import lib.utils as ut\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim.models.word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = xml.readXML(\"../database/TASS/TASS2017/task1-Training.xml\",[0,1,2,3])\n",
    "val_docs   = xml.readXML(\"../database/TASS/TASS2017/task1-Development.xml\",[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets = []\n",
    "train_labels = []\n",
    "for doc in train_docs:\n",
    "    # train_tweets.append(ut.tokenize(doc.content, 0)['clean'])\n",
    "    train_tweets.append(doc.content)\n",
    "    train_labels.append(doc.polarity)\n",
    "\n",
    "val_tweets = []\n",
    "val_labels = []\n",
    "for doc in val_docs:\n",
    "    # test_tweets.append(ut.tokenize(doc.content, 0)['clean'])\n",
    "    val_tweets.append(doc.content)\n",
    "    val_labels.append(doc.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 506)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tweets), len(val_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sentences = 418\n",
      "       \r",
      "Negative Sentences = 318\n",
      "       \r",
      "Neutral  Sentences = 133\n",
      "       \r",
      "None Values        = 139\n"
     ]
    }
   ],
   "source": [
    "POSI_train_docs = [train_docs[i] for i in range(len(train_labels)) if train_labels[i] == 0]\n",
    "NEGA_train_docs = [train_docs[i] for i in range(len(train_labels)) if train_labels[i] == 1]\n",
    "NEUT_train_docs = [train_docs[i] for i in range(len(train_labels)) if train_labels[i] == 2]\n",
    "NONE_train_docs = [train_docs[i] for i in range(len(train_labels)) if train_labels[i] == 3]\n",
    "\n",
    "level_train_docs = [POSI_train_docs,NEGA_train_docs,NEUT_train_docs,NONE_train_docs]\n",
    "\n",
    "fmt = \"\"\"Positive Sentences = {:d}\n",
    "       \\rNegative Sentences = {:d}\n",
    "       \\rNeutral  Sentences = {:d}\n",
    "       \\rNone Values        = {:d}\"\"\"\n",
    "\n",
    "print(fmt.format(len(POSI_train_docs),\n",
    "                 len(NEGA_train_docs),\n",
    "                 len(NEUT_train_docs),\n",
    "                 len(NONE_train_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of sentences per level :  133\n"
     ]
    }
   ],
   "source": [
    "minSentLvl = min(len(POSI_train_docs),len(NEGA_train_docs),len(NEUT_train_docs),len(NONE_train_docs))\n",
    "\n",
    "print('Minimum number of sentences per level : ', minSentLvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "new_train_docs = []\n",
    "for i in range(len(level_train_docs)):\n",
    "    level_per = random.sample(level_train_docs[i],len(level_train_docs[i]))\n",
    "    new_train_docs.append(level_per[:minSentLvl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New size of sentences:\n",
      "\n",
      "Positive Sentences = 133\n",
      "       \r",
      "Negative Sentences = 133\n",
      "       \r",
      "Neutral  Sentences = 133\n",
      "       \r",
      "None Values        = 133\n"
     ]
    }
   ],
   "source": [
    "print(\"New size of sentences:\\n\")\n",
    "fmt = \"\"\"Positive Sentences = {:d}\n",
    "       \\rNegative Sentences = {:d}\n",
    "       \\rNeutral  Sentences = {:d}\n",
    "       \\rNone Values        = {:d}\"\"\"\n",
    "\n",
    "print(fmt.format(len(new_train_docs[0]),\n",
    "                 len(new_train_docs[1]),\n",
    "                 len(new_train_docs[2]),\n",
    "                 len(new_train_docs[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuf_train_docs size =  532\n"
     ]
    }
   ],
   "source": [
    "flat_train_docs = [item for sublist in new_train_docs for item in sublist]\n",
    "shuf_train_docs = random.sample(flat_train_docs,len(flat_train_docs))\n",
    "\n",
    "assert (len(shuf_train_docs) == 4 * minSentLvl)\n",
    "print(\"shuf_train_docs size = \", len(shuf_train_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for doc in shuf_train_docs + val_docs:\n",
    "    corpus.append(doc.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences =  1038\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences = \", (len(val_docs + shuf_train_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuf_train_labels = []\n",
    "for doc in shuf_train_docs:\n",
    "    shuf_train_labels.append(doc.polarity)\n",
    "    \n",
    "assert (len(shuf_train_labels) == len(shuf_train_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = CountVectorizer(tokenizer=ut.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1038, 3976)\n"
     ]
    }
   ],
   "source": [
    "X = counter.fit_transform(corpus)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs   = xml.readXMLTest(\"../database/TASS/TASS2017/task1-Test.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = []\n",
    "for doc in test_docs:\n",
    "    test_tweets.append(doc.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(test_tweets) == 1899)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for tweet in corpus + test_tweets:\n",
    "    sentence = []\n",
    "    for word in ut.tokenizer(tweet):\n",
    "        sentence.append(word)\n",
    "    sequences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(sequences) == (len(shuf_train_docs) + len(val_docs) + len(test_tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter(word for doc in sequences for word in doc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8333)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt['felicidad'], len(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('agobio', 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.most_common()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('que', 1720),\n",
       " ('de', 1518),\n",
       " ('y', 1042),\n",
       " ('a', 986),\n",
       " ('no', 914),\n",
       " ('la', 904),\n",
       " ('el', 823),\n",
       " ('me', 811),\n",
       " ('en', 793),\n",
       " ('es', 743)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8335"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "max_vocab = len(cnt)\n",
    "min_freq = 0\n",
    "#max_vocab = len(cnt)\n",
    "#max_vocab = 4000\n",
    "#min_freq  = 0\n",
    "\n",
    "\n",
    "itos = [o for o,c in cnt.most_common(max_vocab) if c >= min_freq]\n",
    "\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')\n",
    "\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8333\n"
     ]
    }
   ],
   "source": [
    "print(len(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8335"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "TASS_     = '2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(itos, open('../database/ulmfit/tmp/itos_'+TASS_+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos      = pickle.load(open('../database/ulmfit/tmp/itos_'+TASS_+'.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ids = [[stoi[o] for o in p] for p in sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(sequences) == len(data_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data train tensor: (532,)\n",
      "Shape of data val  tensor: (506,)\n",
      "Shape of data test  tensor: (1899,)\n"
     ]
    }
   ],
   "source": [
    "x_train_ids = np.array(data_ids[:len(shuf_train_labels)])\n",
    "x_val_ids   = np.array(data_ids[len(shuf_train_labels):len(shuf_train_labels)+len(val_docs)])\n",
    "x_test_ids  = np.array(data_ids[(len(shuf_train_labels)+len(val_docs)):])\n",
    "\n",
    "print('Shape of data train tensor:', x_train_ids.shape)\n",
    "print('Shape of data val  tensor:', x_val_ids.shape)\n",
    "print('Shape of data test  tensor:', x_test_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = '../database/ulmfit/'\n",
    "\n",
    "np.save(SAVE_PATH + \"tmp/train_labels_\"+TASS_+\".npy\",shuf_train_labels)\n",
    "np.save(SAVE_PATH + \"tmp/val_labels_\"+TASS_+\".npy\",val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(SAVE_PATH + \"tmp/train_ids_\"+TASS_+\".npy\",x_train_ids)\n",
    "np.save(SAVE_PATH + \"tmp/val_ids_\"+TASS_+\".npy\",x_val_ids)\n",
    "np.save(SAVE_PATH + \"tmp/test_ids_\"+TASS_+\".npy\",x_test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lo',\n",
       " 'mismo',\n",
       " 'puedo',\n",
       " 'decir',\n",
       " 'de',\n",
       " 'tu',\n",
       " 'fanart',\n",
       " 'y',\n",
       " 'por',\n",
       " 'cierto',\n",
       " 'tu',\n",
       " 'comic',\n",
       " 'muy',\n",
       " 'divertido']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_',\n",
       " '_pad_',\n",
       " 'que',\n",
       " 'de',\n",
       " 'y',\n",
       " 'a',\n",
       " 'no',\n",
       " 'la',\n",
       " 'el',\n",
       " 'me',\n",
       " 'en',\n",
       " 'es',\n",
       " 'lo',\n",
       " 'un',\n",
       " 'por',\n",
       " 'pero',\n",
       " 'se',\n",
       " 'si',\n",
       " 'los',\n",
       " 'mi',\n",
       " 'con',\n",
       " 'una',\n",
       " 'ya',\n",
       " 'las',\n",
       " 'para',\n",
       " 'te',\n",
       " 'yo',\n",
       " 'mas',\n",
       " 'al',\n",
       " 'como',\n",
       " 'muy',\n",
       " 'esta',\n",
       " 'tengo',\n",
       " 'estoy',\n",
       " 'he',\n",
       " 'del',\n",
       " 'gracias',\n",
       " 'tu',\n",
       " 'ha',\n",
       " 'dia',\n",
       " 'porque',\n",
       " 'cuando',\n",
       " 'o',\n",
       " 'os',\n",
       " 'ver',\n",
       " 'soy',\n",
       " 'son',\n",
       " 'eso',\n",
       " 'todo',\n",
       " 'solo',\n",
       " 'asi',\n",
       " 'quiero',\n",
       " 'hay',\n",
       " 'le',\n",
       " 'bueno',\n",
       " 'bien',\n",
       " 'tan',\n",
       " 'ahora',\n",
       " 'hoy',\n",
       " 'nos',\n",
       " 'mejor',\n",
       " 'ma',\n",
       " 'vez',\n",
       " 'ser',\n",
       " 'hacer',\n",
       " 'q',\n",
       " 'dias',\n",
       " 'sin',\n",
       " 'voy',\n",
       " 'todos',\n",
       " 'pues',\n",
       " 'ana',\n",
       " 'este',\n",
       " 'ni',\n",
       " 'hace',\n",
       " 'nada',\n",
       " 'va',\n",
       " 'menos',\n",
       " 'mucho',\n",
       " 'poco',\n",
       " 'algo',\n",
       " 'tambien',\n",
       " 'muchas',\n",
       " 'vida',\n",
       " 'feliz',\n",
       " 'ir',\n",
       " 'cosas',\n",
       " 'gente',\n",
       " 'eres',\n",
       " 'siempre',\n",
       " 'tiene',\n",
       " 'buen',\n",
       " 'mal',\n",
       " 'dos',\n",
       " 'puedo',\n",
       " 'mismo',\n",
       " 'tio',\n",
       " 'tener',\n",
       " 'buena',\n",
       " 'aqui',\n",
       " 'verdad',\n",
       " 'mis',\n",
       " 'alguien',\n",
       " 'ese',\n",
       " 'da',\n",
       " 'genial',\n",
       " 'gran',\n",
       " 'su',\n",
       " 'noche',\n",
       " 'aunque',\n",
       " 'esa',\n",
       " 'esto',\n",
       " 'buenos',\n",
       " 'espero',\n",
       " 'creo',\n",
       " 'estas',\n",
       " 'hasta',\n",
       " 'era',\n",
       " 'nuevo',\n",
       " 'claro',\n",
       " 'han',\n",
       " 'gusta',\n",
       " 'horas',\n",
       " 'semana',\n",
       " 'estar',\n",
       " 'super',\n",
       " 'otra',\n",
       " 'casa',\n",
       " 'desde',\n",
       " 'sea',\n",
       " 'despues',\n",
       " 'aun',\n",
       " 'cada',\n",
       " 'uno',\n",
       " 'tienes',\n",
       " 'hola',\n",
       " 'tiempo',\n",
       " 'hecho',\n",
       " 'igual',\n",
       " 'tarde',\n",
       " 'estan',\n",
       " 'jajaja',\n",
       " 'otro',\n",
       " 'video',\n",
       " 'serio',\n",
       " 'bonito',\n",
       " 'final',\n",
       " 'sido',\n",
       " 'parece',\n",
       " 'vamos',\n",
       " 'cierto',\n",
       " 'seguro',\n",
       " 'tanto',\n",
       " 'puta',\n",
       " 'triste',\n",
       " 'vale',\n",
       " 'verano',\n",
       " 'puede',\n",
       " 'veo',\n",
       " 'ao',\n",
       " 'fin',\n",
       " 'mala',\n",
       " 'nunca',\n",
       " 'quien',\n",
       " 'pa',\n",
       " 'estaba',\n",
       " 'donde',\n",
       " 'ganas',\n",
       " 'algun',\n",
       " 'dice',\n",
       " 'madrid',\n",
       " 'antes',\n",
       " 'malo',\n",
       " 'pasa',\n",
       " 'veces',\n",
       " 'mundo',\n",
       " 'digo',\n",
       " 'sabes',\n",
       " 'fue',\n",
       " 'primera',\n",
       " 'has',\n",
       " 'espa',\n",
       " 'dormir',\n",
       " 'queda',\n",
       " 'peor',\n",
       " 'sera',\n",
       " 'luego',\n",
       " 'falta',\n",
       " 'fotos',\n",
       " 'pasado',\n",
       " 'foto',\n",
       " 'cosa',\n",
       " 'peque',\n",
       " 'persona',\n",
       " 'vaya',\n",
       " 'calor',\n",
       " 'directo',\n",
       " 'tenemos',\n",
       " 'pobre',\n",
       " 'abrazo',\n",
       " 'casi',\n",
       " 'parte',\n",
       " 'visto',\n",
       " 'ay',\n",
       " 'grande',\n",
       " 'trabajo',\n",
       " 'ves',\n",
       " 'as',\n",
       " 'mes',\n",
       " 'nueva',\n",
       " 'tampoco',\n",
       " 'amigos',\n",
       " 'seria',\n",
       " 'sus',\n",
       " 'sobre',\n",
       " 'sabe',\n",
       " 'dicho',\n",
       " 'cara',\n",
       " 'suerte',\n",
       " 'acabo',\n",
       " 'ultimo',\n",
       " 'ojala',\n",
       " 'encima',\n",
       " 'llevo',\n",
       " 'muchos',\n",
       " 'decir',\n",
       " 'primer',\n",
       " 'les',\n",
       " 'puedes',\n",
       " 'conmigo',\n",
       " 'mejores',\n",
       " 'iba',\n",
       " 'tienen',\n",
       " 'e',\n",
       " 'pronto',\n",
       " 'jugar',\n",
       " 'pena',\n",
       " 'jaja',\n",
       " 'estamos',\n",
       " 'jo',\n",
       " 'poner',\n",
       " 'ti',\n",
       " 'nadie',\n",
       " 'somos',\n",
       " 'favor',\n",
       " 'poder',\n",
       " 'pasar',\n",
       " 'eh',\n",
       " 'unico',\n",
       " 'vacaciones',\n",
       " 'cuenta',\n",
       " 'tal',\n",
       " 'ella',\n",
       " 'juego',\n",
       " 'poquito',\n",
       " 'septiembre',\n",
       " 'vuelta',\n",
       " 'momento',\n",
       " 'demasiado',\n",
       " 'buenas',\n",
       " 'temporada',\n",
       " 'contigo',\n",
       " 'ayer',\n",
       " 'sola',\n",
       " 'proxima',\n",
       " 'bonita',\n",
       " 'haber',\n",
       " 'saber',\n",
       " 'normal',\n",
       " 'libro',\n",
       " 'mierda',\n",
       " 'hora',\n",
       " 'viene',\n",
       " 'ido',\n",
       " 'duro',\n",
       " 'unos',\n",
       " 'toda',\n",
       " 'dar',\n",
       " 'hemos',\n",
       " 'ademas',\n",
       " 'habia',\n",
       " 'enhorabuena',\n",
       " 'tenia',\n",
       " 'amigo',\n",
       " 'siento',\n",
       " 'rt',\n",
       " 'hablar',\n",
       " 'mil',\n",
       " 'facil',\n",
       " 'pelo',\n",
       " 'estado',\n",
       " 'posible',\n",
       " 'otros',\n",
       " 'd',\n",
       " 'esas',\n",
       " 'acaba',\n",
       " 'sabeis',\n",
       " 'madre',\n",
       " 'tus',\n",
       " 'segunda',\n",
       " 'nuestras',\n",
       " 'habra',\n",
       " 'hombre',\n",
       " 'haces',\n",
       " 'puesto',\n",
       " 'movil',\n",
       " 'muchisimas',\n",
       " 'esos',\n",
       " 'primero',\n",
       " 'ellos',\n",
       " 'necesito',\n",
       " 'imposible',\n",
       " 'unas',\n",
       " 'lunes',\n",
       " 'ahi',\n",
       " 'lado',\n",
       " 'toca',\n",
       " 'deja',\n",
       " 'entiendo',\n",
       " 'mucha',\n",
       " 'fuerte',\n",
       " 'oye',\n",
       " 'sue',\n",
       " 'guapa',\n",
       " 'sabado',\n",
       " 'estos',\n",
       " 'plan',\n",
       " 'haya',\n",
       " 'entre',\n",
       " 'muchisimo',\n",
       " 'siguiente',\n",
       " 'sale',\n",
       " 'especial',\n",
       " 'tenido',\n",
       " 'justo',\n",
       " 'vosotros',\n",
       " 'sigo',\n",
       " 'hago',\n",
       " 'pais',\n",
       " 'nuestra',\n",
       " 'nuestro',\n",
       " 'twitter',\n",
       " 'jajajaja',\n",
       " 'caso',\n",
       " 'dado',\n",
       " 'medio',\n",
       " 'algunos',\n",
       " 'entonces',\n",
       " 'mira',\n",
       " 'podemos',\n",
       " 'verlo',\n",
       " 'opinion',\n",
       " 'm',\n",
       " 'queria',\n",
       " 'minutos',\n",
       " 'ultima',\n",
       " 'venga',\n",
       " 'dan',\n",
       " 'paso',\n",
       " 'echo',\n",
       " 'quedan',\n",
       " 'ah',\n",
       " 'mensaje',\n",
       " 'hacia',\n",
       " 'dices',\n",
       " 'pongo',\n",
       " 'todas',\n",
       " 'alegro',\n",
       " 'k',\n",
       " 'cumplea',\n",
       " 'preciosa',\n",
       " 'importante',\n",
       " 'extra',\n",
       " 'videos',\n",
       " 'ninguno',\n",
       " 'encantado',\n",
       " 'seguir',\n",
       " 'bonitas',\n",
       " 'van',\n",
       " 'sabia',\n",
       " 'vuelto',\n",
       " 'puto',\n",
       " 'vi',\n",
       " 'cualquier',\n",
       " 'hacen',\n",
       " 'llorar',\n",
       " 'hare',\n",
       " 'felicidades',\n",
       " 'llegar',\n",
       " 'rapido',\n",
       " 'vas',\n",
       " 'canal',\n",
       " 'teneis',\n",
       " 'siendo',\n",
       " 'personas',\n",
       " 'gustaria',\n",
       " 'doy',\n",
       " 'domingo',\n",
       " 'conozco',\n",
       " 'otras',\n",
       " 'noches',\n",
       " 'sol',\n",
       " 'pelicula',\n",
       " 'ja',\n",
       " 'volver',\n",
       " 'tranquilo',\n",
       " 'pienso',\n",
       " 'verla',\n",
       " 'duele',\n",
       " 'dificil',\n",
       " 'joder',\n",
       " 'animo',\n",
       " 'largo',\n",
       " 'haciendo',\n",
       " 'pone',\n",
       " 'interesante',\n",
       " 'amor',\n",
       " 'escuchar',\n",
       " 'odio',\n",
       " 'pueblo',\n",
       " 'hacerme',\n",
       " 'podria',\n",
       " 'duda',\n",
       " 'gracia',\n",
       " 'compa',\n",
       " 'juntos',\n",
       " 'todavia',\n",
       " 'espera',\n",
       " 'version',\n",
       " 'agua',\n",
       " 'quieres',\n",
       " 'trabajar',\n",
       " 'vuestro',\n",
       " 'leido',\n",
       " 'dinero',\n",
       " 'to',\n",
       " 'sigue',\n",
       " 'salir',\n",
       " 'miedo',\n",
       " 'quedo',\n",
       " 'saludos',\n",
       " 'fuera',\n",
       " 'mayor',\n",
       " 'partido',\n",
       " 'valencia',\n",
       " 'tema',\n",
       " 'encontrar',\n",
       " 'alguna',\n",
       " 'ingles',\n",
       " 'increible',\n",
       " 'oficial',\n",
       " 'stream',\n",
       " 'equipo',\n",
       " 'muerte',\n",
       " 'amiga',\n",
       " 'realidad',\n",
       " 'vivo',\n",
       " 'tuit',\n",
       " 'quiere',\n",
       " 'viaje',\n",
       " 'cambiar',\n",
       " 'real',\n",
       " 'h',\n",
       " 'comer',\n",
       " 'programa',\n",
       " 'sad',\n",
       " 'libros',\n",
       " 'nuevas',\n",
       " 'viendo',\n",
       " 'viernes',\n",
       " 'grupo',\n",
       " 'privado',\n",
       " 'alli',\n",
       " 'tweet',\n",
       " 'quedado',\n",
       " 'dormido',\n",
       " 'tia',\n",
       " 'queremos',\n",
       " 'co',\n",
       " 'so',\n",
       " 'gracioso',\n",
       " 'na',\n",
       " 'clases',\n",
       " 'encanta',\n",
       " 'contra',\n",
       " 'youtube',\n",
       " 'gustan',\n",
       " 'cabeza',\n",
       " 'perdido',\n",
       " 'bonitos',\n",
       " 'dicen',\n",
       " 'primeros',\n",
       " 'canciones',\n",
       " 'conocer',\n",
       " 'hablando',\n",
       " 'perfecto',\n",
       " 'mia',\n",
       " 'mar',\n",
       " 'merece',\n",
       " 'empiezan',\n",
       " 'ado',\n",
       " 'l',\n",
       " 'camino',\n",
       " 'aprender',\n",
       " 'problema',\n",
       " 'muerto',\n",
       " 'imagino',\n",
       " 'cari',\n",
       " 'encuentro',\n",
       " 'piensa',\n",
       " 'dolor',\n",
       " 'mola',\n",
       " 'md',\n",
       " 'felices',\n",
       " 'empezar',\n",
       " 'guay',\n",
       " 'proximo',\n",
       " 'bastante',\n",
       " 'examen',\n",
       " 'deseo',\n",
       " 'llego',\n",
       " 'nosotros',\n",
       " 'fiesta',\n",
       " 'negro',\n",
       " 'punto',\n",
       " 'dejo',\n",
       " 'echar',\n",
       " 'idea',\n",
       " 'felicidad',\n",
       " 'pase',\n",
       " 'lejos',\n",
       " 'playa',\n",
       " 'fuertes',\n",
       " 'sois',\n",
       " 'ff',\n",
       " 'pense',\n",
       " 'serie',\n",
       " 'problemas',\n",
       " 'sigues',\n",
       " 'quedamos',\n",
       " 'i',\n",
       " 'frio',\n",
       " 'dio',\n",
       " 'mientras',\n",
       " 'termino',\n",
       " 'tonta',\n",
       " 'chicas',\n",
       " 'pokemon',\n",
       " 'palabras',\n",
       " 'b',\n",
       " 'liga',\n",
       " 'clase',\n",
       " 'informacion',\n",
       " 'ello',\n",
       " 'pls',\n",
       " 'haga',\n",
       " 'pido',\n",
       " 'pensaba',\n",
       " 'pagina',\n",
       " 'acabado',\n",
       " 'cine',\n",
       " 'ps',\n",
       " 'cancion',\n",
       " 'sino',\n",
       " 'funciona',\n",
       " 'habla',\n",
       " 'etc',\n",
       " 'tb',\n",
       " 'acompa',\n",
       " 'ayuda',\n",
       " 'vuestra',\n",
       " 'pq',\n",
       " 'podre',\n",
       " 'precioso',\n",
       " 'preguntas',\n",
       " 'hice',\n",
       " 'cuantos',\n",
       " 'curro',\n",
       " 'mano',\n",
       " 'sentido',\n",
       " 'color',\n",
       " 'supuesto',\n",
       " 'empiezo',\n",
       " 'chica',\n",
       " 'leer',\n",
       " 'salen',\n",
       " 'misma',\n",
       " 'recuerdo',\n",
       " 'raro',\n",
       " 'forma',\n",
       " 'roja',\n",
       " 'gusto',\n",
       " 'segundo',\n",
       " 'gobierno',\n",
       " 'meses',\n",
       " 'rollo',\n",
       " 'mio',\n",
       " 'jajajajaja',\n",
       " 'grandes',\n",
       " 'tipo',\n",
       " 'cumple',\n",
       " 'puse',\n",
       " 'musica',\n",
       " 'compartir',\n",
       " 'verte',\n",
       " 'nivel',\n",
       " 'voz',\n",
       " 'premio',\n",
       " 'arte',\n",
       " 'sacar',\n",
       " 'fiestas',\n",
       " 'llegue',\n",
       " 'dejado',\n",
       " 'bajo',\n",
       " 'experiencia',\n",
       " 'hablamos',\n",
       " 'deberia',\n",
       " 'luz',\n",
       " 'online',\n",
       " 'suena',\n",
       " 'unica',\n",
       " 'sitio',\n",
       " 'sesion',\n",
       " 'opcion',\n",
       " 'pasando',\n",
       " 'ire',\n",
       " 'lugar',\n",
       " 'barcelona',\n",
       " 'quedar',\n",
       " 'perro',\n",
       " 'euros',\n",
       " 'vemos',\n",
       " 'bus',\n",
       " 'mujeres',\n",
       " 'pocas',\n",
       " 'mismas',\n",
       " 'hizo',\n",
       " 'par',\n",
       " 'entiende',\n",
       " 'esperando',\n",
       " 'or',\n",
       " 'post',\n",
       " 'tw',\n",
       " 'ultimamente',\n",
       " 'fiebre',\n",
       " 'murcia',\n",
       " 'diga',\n",
       " 'podeis',\n",
       " 'besos',\n",
       " 'disfruta',\n",
       " 'vuelvo',\n",
       " 'noticia',\n",
       " 'contrato',\n",
       " 'respuesta',\n",
       " 'cama',\n",
       " 'darle',\n",
       " 'lider',\n",
       " 'barato',\n",
       " 'tras',\n",
       " 'quereis',\n",
       " 'loco',\n",
       " 'hermana',\n",
       " 'camiseta',\n",
       " 'respeto',\n",
       " 'iguales',\n",
       " 'pensar',\n",
       " 'manera',\n",
       " 'ciudad',\n",
       " 'concierto',\n",
       " 'esque',\n",
       " 'griego',\n",
       " 'fifa',\n",
       " 'cambio',\n",
       " 'edicion',\n",
       " 'maldita',\n",
       " 'mayores',\n",
       " 'malos',\n",
       " 'sere',\n",
       " 'cola',\n",
       " 'capaz',\n",
       " 'cago',\n",
       " 'placer',\n",
       " 'mail',\n",
       " 'semanas',\n",
       " 'pregunta',\n",
       " 'rara',\n",
       " 'razon',\n",
       " 'volvemos',\n",
       " 'verde',\n",
       " 'ba',\n",
       " 'veras',\n",
       " 'lol',\n",
       " 'tren',\n",
       " 'jeje',\n",
       " 'subir',\n",
       " 'instagram',\n",
       " 'pagar',\n",
       " 'san',\n",
       " 'acuerdo',\n",
       " 'usar',\n",
       " 'cena',\n",
       " 'piso',\n",
       " 'libres',\n",
       " 'tele',\n",
       " 'bcn',\n",
       " 'partida',\n",
       " 'tod',\n",
       " 'derecha',\n",
       " 'lleva',\n",
       " 'coger',\n",
       " 'carrera',\n",
       " 'existe',\n",
       " 'uso',\n",
       " 'cual',\n",
       " 'parecido',\n",
       " 'uf',\n",
       " 'poniendo',\n",
       " 'gb',\n",
       " 'estudiar',\n",
       " 'chico',\n",
       " 'daba',\n",
       " 'espacio',\n",
       " 'miercoles',\n",
       " 'tres',\n",
       " 'horrible',\n",
       " 'historia',\n",
       " 'facebook',\n",
       " 'mujer',\n",
       " 'pi',\n",
       " 'dios',\n",
       " 'guapo',\n",
       " 'sorteo',\n",
       " 'guste',\n",
       " 'juegos',\n",
       " 'pensando',\n",
       " 'regalo',\n",
       " 've',\n",
       " 'bienvenida',\n",
       " 'cansado',\n",
       " 'estara',\n",
       " 'pantalla',\n",
       " 'libre',\n",
       " 'familia',\n",
       " 'padre',\n",
       " 'hayas',\n",
       " 'dejar',\n",
       " 'hablaba',\n",
       " 'pases',\n",
       " 'ellas',\n",
       " 'portatil',\n",
       " 'mario',\n",
       " 'centro',\n",
       " 'pinta',\n",
       " 'salga',\n",
       " 'demas',\n",
       " 'dejan',\n",
       " 'pueda',\n",
       " 'cuesta',\n",
       " 'delante',\n",
       " 'disfrutar',\n",
       " 'realmente',\n",
       " 'divertido',\n",
       " 'dime',\n",
       " 'teniendo',\n",
       " 'evitar',\n",
       " 'futuro',\n",
       " 'bilbao',\n",
       " 'ds',\n",
       " 'pasad',\n",
       " 'hija',\n",
       " 'empezado',\n",
       " 'hablo',\n",
       " 'habeis',\n",
       " 'nuevos',\n",
       " 's',\n",
       " 'marca',\n",
       " 'pedir',\n",
       " 'beso',\n",
       " 'chino',\n",
       " 'dentro',\n",
       " 'amo',\n",
       " 'gratis',\n",
       " 'imaginaba',\n",
       " 'contrario',\n",
       " 'darme',\n",
       " 'cuantas',\n",
       " 'bonica',\n",
       " 'propia',\n",
       " 'fan',\n",
       " 'original',\n",
       " 'eran',\n",
       " 'gafas',\n",
       " 'estare',\n",
       " 'significa',\n",
       " 'cenar',\n",
       " 'perder',\n",
       " 'hijo',\n",
       " 'deseando',\n",
       " 'leyendo',\n",
       " 'risas',\n",
       " 'hacerte',\n",
       " 'x',\n",
       " 'amable',\n",
       " 'compra',\n",
       " 'ojo',\n",
       " 'abrir',\n",
       " 'complicado',\n",
       " 'terminar',\n",
       " 'arriba',\n",
       " 'supongo',\n",
       " 'alta',\n",
       " 'moviles',\n",
       " 'depresion',\n",
       " 'durante',\n",
       " 'comprar',\n",
       " 'saludo',\n",
       " 'hacerlo',\n",
       " 'educacion',\n",
       " 'tendria',\n",
       " 'hermosa',\n",
       " 'tranquila',\n",
       " 'ojos',\n",
       " 'ero',\n",
       " 'mu',\n",
       " 'querida',\n",
       " 'tengas',\n",
       " 'nuestros',\n",
       " 'cojo',\n",
       " 'ex',\n",
       " 'roto',\n",
       " 'morir',\n",
       " 'empieza',\n",
       " 'cuarto',\n",
       " 'conocerte',\n",
       " 'malaga',\n",
       " 'luchar',\n",
       " 'juan',\n",
       " 'ejemplo',\n",
       " 'quieras',\n",
       " 'broma',\n",
       " 'xd',\n",
       " 'emo',\n",
       " 'sonrisa',\n",
       " 'conocido',\n",
       " 'bar',\n",
       " 'pc',\n",
       " 'anoche',\n",
       " 'maravilloso',\n",
       " 'cae',\n",
       " 'caen',\n",
       " 'irme',\n",
       " 'c',\n",
       " 'instituto',\n",
       " 'club',\n",
       " 'nombre',\n",
       " 'pones',\n",
       " 'estupendo',\n",
       " 'dise',\n",
       " 'cuanto',\n",
       " 'acabar',\n",
       " 'nota',\n",
       " 'suelo',\n",
       " 'hacemos',\n",
       " 'gala',\n",
       " 'cansada',\n",
       " 'bon',\n",
       " 'escribenos',\n",
       " 'seas',\n",
       " 'leche',\n",
       " 'bienvenido',\n",
       " 'jodido',\n",
       " 'elecciones',\n",
       " 'corazon',\n",
       " 'capitulo',\n",
       " 'esperar',\n",
       " 'fui',\n",
       " 'anda',\n",
       " 'das',\n",
       " 'diciendo',\n",
       " 'veia',\n",
       " 'malas',\n",
       " 'pasan',\n",
       " 'fijo',\n",
       " 'ponerme',\n",
       " 'dijo',\n",
       " 'vengo',\n",
       " 'sensacion',\n",
       " 'apoyo',\n",
       " 'pizza',\n",
       " 'ultimos',\n",
       " 'go',\n",
       " 'seguimos',\n",
       " 'usted',\n",
       " 'iria',\n",
       " 'my',\n",
       " 'finde',\n",
       " 'dura',\n",
       " 'acaso',\n",
       " 'calle',\n",
       " 'mente',\n",
       " 'alla',\n",
       " 'total',\n",
       " 'querido',\n",
       " 'apetece',\n",
       " 'felicitar',\n",
       " 'suficiente',\n",
       " 'incluso',\n",
       " 'culo',\n",
       " 'u',\n",
       " 'internet',\n",
       " 'oportunidad',\n",
       " 'entrar',\n",
       " 'orgullosa',\n",
       " 'querer',\n",
       " 'puedas',\n",
       " 'gh',\n",
       " 'curso',\n",
       " 'comic',\n",
       " 'gilipollas',\n",
       " 'compras',\n",
       " 'prat',\n",
       " 'jaj',\n",
       " 'mirando',\n",
       " 'sorry',\n",
       " 'bajon',\n",
       " 'ilusion',\n",
       " 'escribo',\n",
       " 'decirte',\n",
       " 'gafe',\n",
       " 'contactar',\n",
       " 'besitos',\n",
       " 'deje',\n",
       " 'salud',\n",
       " 'subnormal',\n",
       " 'entero',\n",
       " 'hombres',\n",
       " 'encantaria',\n",
       " 'ningun',\n",
       " 'oh',\n",
       " 'gordo',\n",
       " 'chicos',\n",
       " 'graciosa',\n",
       " 'cuestion',\n",
       " 'caro',\n",
       " 'aviso',\n",
       " 'podriais',\n",
       " 'pendiente',\n",
       " 'cerca',\n",
       " 'biblioteca',\n",
       " 'humor',\n",
       " 'noviembre',\n",
       " 't',\n",
       " 'espalda',\n",
       " 'quedada',\n",
       " 'mejorando',\n",
       " 'nerviosa',\n",
       " 'contenta',\n",
       " 'breve',\n",
       " 'beber',\n",
       " 'maja',\n",
       " 'fav',\n",
       " 'totalmente',\n",
       " 'comida',\n",
       " 'frases',\n",
       " 'entra',\n",
       " 'ciego',\n",
       " 'thanks',\n",
       " 'parada',\n",
       " 'pelis',\n",
       " 'quiera',\n",
       " 'lista',\n",
       " 'padres',\n",
       " 'peli',\n",
       " 'debes',\n",
       " 'ok',\n",
       " 'ta',\n",
       " 'preparando',\n",
       " 'segun',\n",
       " 'debe',\n",
       " 'zona',\n",
       " 'haberme',\n",
       " 'comprado',\n",
       " 'tarjeta',\n",
       " 'profesional',\n",
       " 'spain',\n",
       " 'zonas',\n",
       " 'horario',\n",
       " 'edad',\n",
       " 'cuentas',\n",
       " 'fans',\n",
       " 'planes',\n",
       " 'cuidado',\n",
       " 'enserio',\n",
       " 'rutina',\n",
       " 'tronos',\n",
       " 'puntos',\n",
       " 'carlos',\n",
       " 'podrias',\n",
       " 'follow',\n",
       " 'vives',\n",
       " ...]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
